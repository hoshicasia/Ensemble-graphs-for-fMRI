{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8ea8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                              import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed, dump\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "from joblib import load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557f7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['RELATIONAL', 'EMOTIONAL', 'GAMBLING', 'MOTOR', 'SOCIAL', 'WM', 'LANGUAGE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2dd0b0",
   "metadata": {},
   "source": [
    "# Creating extended vertices features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab354f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fmri_features(time_series):\n",
    "    from scipy.stats import skew, kurtosis, linregress\n",
    "    from statsmodels.tsa.stattools import acf\n",
    "    from scipy.signal import find_peaks\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    n_timepoints = time_series.shape[1]\n",
    "\n",
    "    autocorr_lag1 = []\n",
    "    n_peaks = []\n",
    "    mean_peak_amp = []           \n",
    "    for ts in time_series:\n",
    "        ts = np.asarray(ts).flatten()  \n",
    "        peaks, properties = find_peaks(ts, height=np.mean(ts))\n",
    "        n_peaks.append(len(peaks))\n",
    "        if len(peaks) > 0:\n",
    "            mean_peak_amp.append(np.mean(ts[peaks]))\n",
    "        else:\n",
    "            mean_peak_amp.append(np.nan)\n",
    "\n",
    "        if len(peaks) > 1:\n",
    "            intervals = np.diff(peaks)\n",
    "            mean_interpeak_interval.append(np.mean(intervals))\n",
    "        else:\n",
    "            mean_interpeak_interval.append(np.nan)\n",
    "\n",
    "        acf_vals = acf(ts, nlags=1)\n",
    "            autocorr_lag1.append(acf_vals[1] if len(acf_vals) > 1 else np.nan)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'mean': time_series.mean(axis=1),\n",
    "        'std': time_series.std(axis=1),\n",
    "        'skewness': skew(time_series, axis=1),\n",
    "        'autocorr_lag1': autocorr_lag1,\n",
    "        'n_peaks': n_peaks,\n",
    "        'mean_peak_amp': mean_peak_amp,\n",
    "        'mean_interpeak_interval': mean_interpeak_interval\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71ea0c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [02:43<00:00, 163.85s/it]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "def load(pickle_path):\n",
    "    try:\n",
    "        return joblib.load(pickle_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {pickle_path}: {e}\")\n",
    "        return None  \n",
    "    \n",
    "source_base = Path(\"split_mean\")\n",
    "destination_base = Path(\"vertices_mean_extended\")\n",
    "#folders = ['RELATIONAL', 'EMOTIONAL', 'GAMBLING', 'MOTOR', 'SOCIAL', 'WM', 'LANGUAGE']\n",
    "folders = ['EMOTIONAL']\n",
    "\n",
    "for folder in tqdm(folders):\n",
    "    source_folder = source_base / folder\n",
    "    for pickle_path in source_folder.glob(\"*.pickle\"):\n",
    "        try:\n",
    "            data = load(pickle_path)\n",
    "            if data is None:\n",
    "                continue  \n",
    "            data = np.hstack(data)\n",
    "            df = pd.DataFrame(data)\n",
    "            data_array = df.values\n",
    "            features_df = extract_fmri_features(data_array)\n",
    "\n",
    "            if \"LR\" in pickle_path.name:\n",
    "                subfolder = \"LR\"\n",
    "            elif \"RL\" in pickle_path.name:\n",
    "                subfolder = \"RL\"\n",
    "            else:\n",
    "                print(f\"Warning: File {pickle_path.name} does not contain 'LR' or 'RL'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            destination_folder = destination_base / folder / subfolder\n",
    "            destination_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            output_path = destination_folder / pickle_path.name\n",
    "            features_df.to_pickle(output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pickle_path}: {e}\")\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec95b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'vertices_mean_extended'  \n",
    "output_dir = 'pairwise_datasets'   \n",
    "pattern = os.path.join(base_dir, '**', '*.pickle')\n",
    "pickle_files = glob.glob(pattern, recursive=True)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "all_files = []\n",
    "for file_path in pickle_files:\n",
    "    data = pd.read_pickle(file_path)\n",
    "    print(file_path)\n",
    "    class_label = file_path.split('_')[4].replace('.pickle', '')\n",
    "    data['class'] = class_label\n",
    "    data['sample_id'] = (file_path.split('/')[3]).split('_')[0]\n",
    "    all_files.append(data)\n",
    "   \n",
    "\n",
    "full_data = pd.concat(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "966b7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.reset_index(inplace=True)\n",
    "full_data.rename(columns={'index': 'vertex'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a84f92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertex</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>skewness</th>\n",
       "      <th>autocorr_lag1</th>\n",
       "      <th>n_peaks</th>\n",
       "      <th>mean_peak_amp</th>\n",
       "      <th>mean_interpeak_interval</th>\n",
       "      <th>class</th>\n",
       "      <th>sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.147010</td>\n",
       "      <td>0.850654</td>\n",
       "      <td>-0.206136</td>\n",
       "      <td>0.328977</td>\n",
       "      <td>21</td>\n",
       "      <td>0.684999</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>rnd</td>\n",
       "      <td>322224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.204570</td>\n",
       "      <td>0.939359</td>\n",
       "      <td>-0.218530</td>\n",
       "      <td>0.643224</td>\n",
       "      <td>20</td>\n",
       "      <td>1.223812</td>\n",
       "      <td>3.947368</td>\n",
       "      <td>rnd</td>\n",
       "      <td>322224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.352507</td>\n",
       "      <td>0.993342</td>\n",
       "      <td>-0.282886</td>\n",
       "      <td>0.060360</td>\n",
       "      <td>26</td>\n",
       "      <td>0.676476</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>rnd</td>\n",
       "      <td>322224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.096319</td>\n",
       "      <td>0.807683</td>\n",
       "      <td>-0.179952</td>\n",
       "      <td>0.358285</td>\n",
       "      <td>21</td>\n",
       "      <td>0.721222</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>rnd</td>\n",
       "      <td>322224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.181171</td>\n",
       "      <td>0.933933</td>\n",
       "      <td>-0.020551</td>\n",
       "      <td>0.253191</td>\n",
       "      <td>25</td>\n",
       "      <td>0.736216</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>rnd</td>\n",
       "      <td>322224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165567</th>\n",
       "      <td>375</td>\n",
       "      <td>-0.238299</td>\n",
       "      <td>0.977066</td>\n",
       "      <td>-0.317467</td>\n",
       "      <td>0.299620</td>\n",
       "      <td>17</td>\n",
       "      <td>0.776802</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>neut</td>\n",
       "      <td>990366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165568</th>\n",
       "      <td>376</td>\n",
       "      <td>-0.349985</td>\n",
       "      <td>0.935441</td>\n",
       "      <td>0.108594</td>\n",
       "      <td>0.115772</td>\n",
       "      <td>17</td>\n",
       "      <td>0.765804</td>\n",
       "      <td>4.062500</td>\n",
       "      <td>neut</td>\n",
       "      <td>990366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165569</th>\n",
       "      <td>377</td>\n",
       "      <td>-0.127553</td>\n",
       "      <td>0.962288</td>\n",
       "      <td>-0.129217</td>\n",
       "      <td>0.335510</td>\n",
       "      <td>20</td>\n",
       "      <td>0.896335</td>\n",
       "      <td>3.526316</td>\n",
       "      <td>neut</td>\n",
       "      <td>990366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165570</th>\n",
       "      <td>378</td>\n",
       "      <td>-0.093324</td>\n",
       "      <td>0.969911</td>\n",
       "      <td>0.057978</td>\n",
       "      <td>0.338253</td>\n",
       "      <td>16</td>\n",
       "      <td>1.071996</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>neut</td>\n",
       "      <td>990366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165571</th>\n",
       "      <td>379</td>\n",
       "      <td>-0.168155</td>\n",
       "      <td>0.846581</td>\n",
       "      <td>-0.377379</td>\n",
       "      <td>0.270809</td>\n",
       "      <td>19</td>\n",
       "      <td>0.643454</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>neut</td>\n",
       "      <td>990366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6165572 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         vertex      mean       std  skewness  autocorr_lag1  n_peaks  \\\n",
       "0             1 -0.147010  0.850654 -0.206136       0.328977       21   \n",
       "1             2  0.204570  0.939359 -0.218530       0.643224       20   \n",
       "2             3 -0.352507  0.993342 -0.282886       0.060360       26   \n",
       "3             4 -0.096319  0.807683 -0.179952       0.358285       21   \n",
       "4             5 -0.181171  0.933933 -0.020551       0.253191       25   \n",
       "...         ...       ...       ...       ...            ...      ...   \n",
       "6165567     375 -0.238299  0.977066 -0.317467       0.299620       17   \n",
       "6165568     376 -0.349985  0.935441  0.108594       0.115772       17   \n",
       "6165569     377 -0.127553  0.962288 -0.129217       0.335510       20   \n",
       "6165570     378 -0.093324  0.969911  0.057978       0.338253       16   \n",
       "6165571     379 -0.168155  0.846581 -0.377379       0.270809       19   \n",
       "\n",
       "         mean_peak_amp  mean_interpeak_interval class sample_id  \n",
       "0             0.684999                 3.750000   rnd    322224  \n",
       "1             1.223812                 3.947368   rnd    322224  \n",
       "2             0.676476                 3.400000   rnd    322224  \n",
       "3             0.721222                 4.000000   rnd    322224  \n",
       "4             0.736216                 3.583333   rnd    322224  \n",
       "...                ...                      ...   ...       ...  \n",
       "6165567       0.776802                 3.875000  neut    990366  \n",
       "6165568       0.765804                 4.062500  neut    990366  \n",
       "6165569       0.896335                 3.526316  neut    990366  \n",
       "6165570       1.071996                 4.333333  neut    990366  \n",
       "6165571       0.643454                 3.611111  neut    990366  \n",
       "\n",
       "[6165572 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data['vertex'] += 1\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edaa8538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">autocorr_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>vertex</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>370</th>\n",
       "      <th>371</th>\n",
       "      <th>372</th>\n",
       "      <th>373</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">100206</th>\n",
       "      <th>0bk</th>\n",
       "      <td>0.893819</td>\n",
       "      <td>0.464748</td>\n",
       "      <td>0.603468</td>\n",
       "      <td>0.851265</td>\n",
       "      <td>0.786838</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.675615</td>\n",
       "      <td>0.695618</td>\n",
       "      <td>0.738377</td>\n",
       "      <td>0.692180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960313</td>\n",
       "      <td>0.935202</td>\n",
       "      <td>0.898046</td>\n",
       "      <td>1.023829</td>\n",
       "      <td>1.020021</td>\n",
       "      <td>0.991788</td>\n",
       "      <td>0.950959</td>\n",
       "      <td>1.041028</td>\n",
       "      <td>0.951495</td>\n",
       "      <td>0.968369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2bk</th>\n",
       "      <td>0.861421</td>\n",
       "      <td>0.487011</td>\n",
       "      <td>0.484680</td>\n",
       "      <td>0.790721</td>\n",
       "      <td>0.769333</td>\n",
       "      <td>0.888625</td>\n",
       "      <td>0.603071</td>\n",
       "      <td>0.553682</td>\n",
       "      <td>0.624310</td>\n",
       "      <td>0.655591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957964</td>\n",
       "      <td>0.962293</td>\n",
       "      <td>0.957600</td>\n",
       "      <td>0.960843</td>\n",
       "      <td>0.924773</td>\n",
       "      <td>0.929355</td>\n",
       "      <td>0.972268</td>\n",
       "      <td>0.979947</td>\n",
       "      <td>0.975403</td>\n",
       "      <td>0.987517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.787456</td>\n",
       "      <td>0.512411</td>\n",
       "      <td>0.583106</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>0.637945</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.628705</td>\n",
       "      <td>0.632117</td>\n",
       "      <td>0.541350</td>\n",
       "      <td>0.452887</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018323</td>\n",
       "      <td>1.066575</td>\n",
       "      <td>1.043297</td>\n",
       "      <td>0.910316</td>\n",
       "      <td>0.977589</td>\n",
       "      <td>0.988025</td>\n",
       "      <td>1.001793</td>\n",
       "      <td>0.944066</td>\n",
       "      <td>0.993105</td>\n",
       "      <td>0.973372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.828420</td>\n",
       "      <td>0.447045</td>\n",
       "      <td>0.599733</td>\n",
       "      <td>0.779001</td>\n",
       "      <td>0.749867</td>\n",
       "      <td>0.697426</td>\n",
       "      <td>0.494070</td>\n",
       "      <td>0.672157</td>\n",
       "      <td>0.662432</td>\n",
       "      <td>0.654740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.994043</td>\n",
       "      <td>0.921388</td>\n",
       "      <td>0.944134</td>\n",
       "      <td>1.049938</td>\n",
       "      <td>1.028949</td>\n",
       "      <td>1.045922</td>\n",
       "      <td>0.959480</td>\n",
       "      <td>0.939064</td>\n",
       "      <td>0.869964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>0.841642</td>\n",
       "      <td>0.583493</td>\n",
       "      <td>0.632507</td>\n",
       "      <td>0.794625</td>\n",
       "      <td>0.773274</td>\n",
       "      <td>0.822869</td>\n",
       "      <td>0.459484</td>\n",
       "      <td>0.604053</td>\n",
       "      <td>0.599757</td>\n",
       "      <td>0.810513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955303</td>\n",
       "      <td>0.976240</td>\n",
       "      <td>0.961123</td>\n",
       "      <td>0.988804</td>\n",
       "      <td>1.013960</td>\n",
       "      <td>1.038079</td>\n",
       "      <td>0.979294</td>\n",
       "      <td>0.943085</td>\n",
       "      <td>0.854481</td>\n",
       "      <td>1.037637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">996782</th>\n",
       "      <th>r</th>\n",
       "      <td>0.727708</td>\n",
       "      <td>0.426522</td>\n",
       "      <td>0.565467</td>\n",
       "      <td>0.729745</td>\n",
       "      <td>0.741279</td>\n",
       "      <td>0.681953</td>\n",
       "      <td>0.512494</td>\n",
       "      <td>0.589251</td>\n",
       "      <td>0.580114</td>\n",
       "      <td>0.472755</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052960</td>\n",
       "      <td>0.964462</td>\n",
       "      <td>0.968415</td>\n",
       "      <td>1.021673</td>\n",
       "      <td>0.966433</td>\n",
       "      <td>0.966144</td>\n",
       "      <td>1.033262</td>\n",
       "      <td>0.962946</td>\n",
       "      <td>0.927782</td>\n",
       "      <td>0.929914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation</th>\n",
       "      <td>0.792886</td>\n",
       "      <td>0.503521</td>\n",
       "      <td>0.550323</td>\n",
       "      <td>0.794583</td>\n",
       "      <td>0.793159</td>\n",
       "      <td>0.763781</td>\n",
       "      <td>0.657890</td>\n",
       "      <td>0.526877</td>\n",
       "      <td>0.735584</td>\n",
       "      <td>0.704892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120857</td>\n",
       "      <td>1.036813</td>\n",
       "      <td>0.975302</td>\n",
       "      <td>1.024739</td>\n",
       "      <td>0.927820</td>\n",
       "      <td>1.015248</td>\n",
       "      <td>0.927360</td>\n",
       "      <td>1.111079</td>\n",
       "      <td>1.036310</td>\n",
       "      <td>1.067334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnd</th>\n",
       "      <td>0.695992</td>\n",
       "      <td>0.790285</td>\n",
       "      <td>0.441623</td>\n",
       "      <td>0.634431</td>\n",
       "      <td>0.858011</td>\n",
       "      <td>0.865658</td>\n",
       "      <td>0.607152</td>\n",
       "      <td>0.557471</td>\n",
       "      <td>0.684295</td>\n",
       "      <td>0.758048</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002791</td>\n",
       "      <td>0.872504</td>\n",
       "      <td>0.941104</td>\n",
       "      <td>1.008072</td>\n",
       "      <td>0.989134</td>\n",
       "      <td>0.865046</td>\n",
       "      <td>0.962983</td>\n",
       "      <td>0.826940</td>\n",
       "      <td>0.882297</td>\n",
       "      <td>0.896415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>0.759290</td>\n",
       "      <td>0.656334</td>\n",
       "      <td>0.785014</td>\n",
       "      <td>0.829183</td>\n",
       "      <td>0.825330</td>\n",
       "      <td>0.800928</td>\n",
       "      <td>0.453851</td>\n",
       "      <td>0.651768</td>\n",
       "      <td>0.789581</td>\n",
       "      <td>0.625014</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043619</td>\n",
       "      <td>0.953864</td>\n",
       "      <td>0.975513</td>\n",
       "      <td>0.990321</td>\n",
       "      <td>1.042829</td>\n",
       "      <td>0.950362</td>\n",
       "      <td>1.015744</td>\n",
       "      <td>0.967266</td>\n",
       "      <td>0.929367</td>\n",
       "      <td>1.004862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win</th>\n",
       "      <td>0.714020</td>\n",
       "      <td>0.346666</td>\n",
       "      <td>0.543389</td>\n",
       "      <td>0.669854</td>\n",
       "      <td>0.706112</td>\n",
       "      <td>0.847998</td>\n",
       "      <td>0.625539</td>\n",
       "      <td>0.694811</td>\n",
       "      <td>0.618224</td>\n",
       "      <td>0.798924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884673</td>\n",
       "      <td>0.928013</td>\n",
       "      <td>0.740692</td>\n",
       "      <td>0.719947</td>\n",
       "      <td>0.821392</td>\n",
       "      <td>1.008698</td>\n",
       "      <td>0.689055</td>\n",
       "      <td>1.015462</td>\n",
       "      <td>0.756253</td>\n",
       "      <td>0.636618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8134 rows × 2274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   autocorr_lag1                                          \\\n",
       "vertex                       1         2         3         4         5     \n",
       "sample_id class                                                            \n",
       "100206    0bk           0.893819  0.464748  0.603468  0.851265  0.786838   \n",
       "          2bk           0.861421  0.487011  0.484680  0.790721  0.769333   \n",
       "          fear          0.787456  0.512411  0.583106  0.750800  0.637945   \n",
       "          l             0.828420  0.447045  0.599733  0.779001  0.749867   \n",
       "          loss          0.841642  0.583493  0.632507  0.794625  0.773274   \n",
       "...                          ...       ...       ...       ...       ...   \n",
       "996782    r             0.727708  0.426522  0.565467  0.729745  0.741279   \n",
       "          relation      0.792886  0.503521  0.550323  0.794583  0.793159   \n",
       "          rnd           0.695992  0.790285  0.441623  0.634431  0.858011   \n",
       "          story         0.759290  0.656334  0.785014  0.829183  0.825330   \n",
       "          win           0.714020  0.346666  0.543389  0.669854  0.706112   \n",
       "\n",
       "                                                                      ...  \\\n",
       "vertex                   6         7         8         9         10   ...   \n",
       "sample_id class                                                       ...   \n",
       "100206    0bk       0.909225  0.675615  0.695618  0.738377  0.692180  ...   \n",
       "          2bk       0.888625  0.603071  0.553682  0.624310  0.655591  ...   \n",
       "          fear      0.806604  0.628705  0.632117  0.541350  0.452887  ...   \n",
       "          l         0.697426  0.494070  0.672157  0.662432  0.654740  ...   \n",
       "          loss      0.822869  0.459484  0.604053  0.599757  0.810513  ...   \n",
       "...                      ...       ...       ...       ...       ...  ...   \n",
       "996782    r         0.681953  0.512494  0.589251  0.580114  0.472755  ...   \n",
       "          relation  0.763781  0.657890  0.526877  0.735584  0.704892  ...   \n",
       "          rnd       0.865658  0.607152  0.557471  0.684295  0.758048  ...   \n",
       "          story     0.800928  0.453851  0.651768  0.789581  0.625014  ...   \n",
       "          win       0.847998  0.625539  0.694811  0.618224  0.798924  ...   \n",
       "\n",
       "                         std                                          \\\n",
       "vertex                   370       371       372       373       374   \n",
       "sample_id class                                                        \n",
       "100206    0bk       0.960313  0.935202  0.898046  1.023829  1.020021   \n",
       "          2bk       0.957964  0.962293  0.957600  0.960843  0.924773   \n",
       "          fear      1.018323  1.066575  1.043297  0.910316  0.977589   \n",
       "          l         0.929404  0.994043  0.921388  0.944134  1.049938   \n",
       "          loss      0.955303  0.976240  0.961123  0.988804  1.013960   \n",
       "...                      ...       ...       ...       ...       ...   \n",
       "996782    r         1.052960  0.964462  0.968415  1.021673  0.966433   \n",
       "          relation  1.120857  1.036813  0.975302  1.024739  0.927820   \n",
       "          rnd       1.002791  0.872504  0.941104  1.008072  0.989134   \n",
       "          story     1.043619  0.953864  0.975513  0.990321  1.042829   \n",
       "          win       0.884673  0.928013  0.740692  0.719947  0.821392   \n",
       "\n",
       "                                                                      \n",
       "vertex                   375       376       377       378       379  \n",
       "sample_id class                                                       \n",
       "100206    0bk       0.991788  0.950959  1.041028  0.951495  0.968369  \n",
       "          2bk       0.929355  0.972268  0.979947  0.975403  0.987517  \n",
       "          fear      0.988025  1.001793  0.944066  0.993105  0.973372  \n",
       "          l         1.028949  1.045922  0.959480  0.939064  0.869964  \n",
       "          loss      1.038079  0.979294  0.943085  0.854481  1.037637  \n",
       "...                      ...       ...       ...       ...       ...  \n",
       "996782    r         0.966144  1.033262  0.962946  0.927782  0.929914  \n",
       "          relation  1.015248  0.927360  1.111079  1.036310  1.067334  \n",
       "          rnd       0.865046  0.962983  0.826940  0.882297  0.896415  \n",
       "          story     0.950362  1.015744  0.967266  0.929367  1.004862  \n",
       "          win       1.008698  0.689055  1.015462  0.756253  0.636618  \n",
       "\n",
       "[8134 rows x 2274 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = full_data.pivot_table(index=['sample_id', 'class'],\n",
    "                              columns='vertex',\n",
    "                              values=['mean', 'std', 'autocorr_lag1', 'n_peaks', 'mean_peak_amp', 'mean_interpeak_interval'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9151958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>class</th>\n",
       "      <th>autocorr_lag1_1</th>\n",
       "      <th>autocorr_lag1_2</th>\n",
       "      <th>autocorr_lag1_3</th>\n",
       "      <th>autocorr_lag1_4</th>\n",
       "      <th>autocorr_lag1_5</th>\n",
       "      <th>autocorr_lag1_6</th>\n",
       "      <th>autocorr_lag1_7</th>\n",
       "      <th>autocorr_lag1_8</th>\n",
       "      <th>...</th>\n",
       "      <th>std_370</th>\n",
       "      <th>std_371</th>\n",
       "      <th>std_372</th>\n",
       "      <th>std_373</th>\n",
       "      <th>std_374</th>\n",
       "      <th>std_375</th>\n",
       "      <th>std_376</th>\n",
       "      <th>std_377</th>\n",
       "      <th>std_378</th>\n",
       "      <th>std_379</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100206</td>\n",
       "      <td>0bk</td>\n",
       "      <td>0.893819</td>\n",
       "      <td>0.464748</td>\n",
       "      <td>0.603468</td>\n",
       "      <td>0.851265</td>\n",
       "      <td>0.786838</td>\n",
       "      <td>0.909225</td>\n",
       "      <td>0.675615</td>\n",
       "      <td>0.695618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960313</td>\n",
       "      <td>0.935202</td>\n",
       "      <td>0.898046</td>\n",
       "      <td>1.023829</td>\n",
       "      <td>1.020021</td>\n",
       "      <td>0.991788</td>\n",
       "      <td>0.950959</td>\n",
       "      <td>1.041028</td>\n",
       "      <td>0.951495</td>\n",
       "      <td>0.968369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100206</td>\n",
       "      <td>2bk</td>\n",
       "      <td>0.861421</td>\n",
       "      <td>0.487011</td>\n",
       "      <td>0.484680</td>\n",
       "      <td>0.790721</td>\n",
       "      <td>0.769333</td>\n",
       "      <td>0.888625</td>\n",
       "      <td>0.603071</td>\n",
       "      <td>0.553682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957964</td>\n",
       "      <td>0.962293</td>\n",
       "      <td>0.957600</td>\n",
       "      <td>0.960843</td>\n",
       "      <td>0.924773</td>\n",
       "      <td>0.929355</td>\n",
       "      <td>0.972268</td>\n",
       "      <td>0.979947</td>\n",
       "      <td>0.975403</td>\n",
       "      <td>0.987517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100206</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.787456</td>\n",
       "      <td>0.512411</td>\n",
       "      <td>0.583106</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>0.637945</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.628705</td>\n",
       "      <td>0.632117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018323</td>\n",
       "      <td>1.066575</td>\n",
       "      <td>1.043297</td>\n",
       "      <td>0.910316</td>\n",
       "      <td>0.977589</td>\n",
       "      <td>0.988025</td>\n",
       "      <td>1.001793</td>\n",
       "      <td>0.944066</td>\n",
       "      <td>0.993105</td>\n",
       "      <td>0.973372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100206</td>\n",
       "      <td>l</td>\n",
       "      <td>0.828420</td>\n",
       "      <td>0.447045</td>\n",
       "      <td>0.599733</td>\n",
       "      <td>0.779001</td>\n",
       "      <td>0.749867</td>\n",
       "      <td>0.697426</td>\n",
       "      <td>0.494070</td>\n",
       "      <td>0.672157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.994043</td>\n",
       "      <td>0.921388</td>\n",
       "      <td>0.944134</td>\n",
       "      <td>1.049938</td>\n",
       "      <td>1.028949</td>\n",
       "      <td>1.045922</td>\n",
       "      <td>0.959480</td>\n",
       "      <td>0.939064</td>\n",
       "      <td>0.869964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100206</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.841642</td>\n",
       "      <td>0.583493</td>\n",
       "      <td>0.632507</td>\n",
       "      <td>0.794625</td>\n",
       "      <td>0.773274</td>\n",
       "      <td>0.822869</td>\n",
       "      <td>0.459484</td>\n",
       "      <td>0.604053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955303</td>\n",
       "      <td>0.976240</td>\n",
       "      <td>0.961123</td>\n",
       "      <td>0.988804</td>\n",
       "      <td>1.013960</td>\n",
       "      <td>1.038079</td>\n",
       "      <td>0.979294</td>\n",
       "      <td>0.943085</td>\n",
       "      <td>0.854481</td>\n",
       "      <td>1.037637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>996782</td>\n",
       "      <td>r</td>\n",
       "      <td>0.727708</td>\n",
       "      <td>0.426522</td>\n",
       "      <td>0.565467</td>\n",
       "      <td>0.729745</td>\n",
       "      <td>0.741279</td>\n",
       "      <td>0.681953</td>\n",
       "      <td>0.512494</td>\n",
       "      <td>0.589251</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052960</td>\n",
       "      <td>0.964462</td>\n",
       "      <td>0.968415</td>\n",
       "      <td>1.021673</td>\n",
       "      <td>0.966433</td>\n",
       "      <td>0.966144</td>\n",
       "      <td>1.033262</td>\n",
       "      <td>0.962946</td>\n",
       "      <td>0.927782</td>\n",
       "      <td>0.929914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>996782</td>\n",
       "      <td>relation</td>\n",
       "      <td>0.792886</td>\n",
       "      <td>0.503521</td>\n",
       "      <td>0.550323</td>\n",
       "      <td>0.794583</td>\n",
       "      <td>0.793159</td>\n",
       "      <td>0.763781</td>\n",
       "      <td>0.657890</td>\n",
       "      <td>0.526877</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120857</td>\n",
       "      <td>1.036813</td>\n",
       "      <td>0.975302</td>\n",
       "      <td>1.024739</td>\n",
       "      <td>0.927820</td>\n",
       "      <td>1.015248</td>\n",
       "      <td>0.927360</td>\n",
       "      <td>1.111079</td>\n",
       "      <td>1.036310</td>\n",
       "      <td>1.067334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>996782</td>\n",
       "      <td>rnd</td>\n",
       "      <td>0.695992</td>\n",
       "      <td>0.790285</td>\n",
       "      <td>0.441623</td>\n",
       "      <td>0.634431</td>\n",
       "      <td>0.858011</td>\n",
       "      <td>0.865658</td>\n",
       "      <td>0.607152</td>\n",
       "      <td>0.557471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002791</td>\n",
       "      <td>0.872504</td>\n",
       "      <td>0.941104</td>\n",
       "      <td>1.008072</td>\n",
       "      <td>0.989134</td>\n",
       "      <td>0.865046</td>\n",
       "      <td>0.962983</td>\n",
       "      <td>0.826940</td>\n",
       "      <td>0.882297</td>\n",
       "      <td>0.896415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>996782</td>\n",
       "      <td>story</td>\n",
       "      <td>0.759290</td>\n",
       "      <td>0.656334</td>\n",
       "      <td>0.785014</td>\n",
       "      <td>0.829183</td>\n",
       "      <td>0.825330</td>\n",
       "      <td>0.800928</td>\n",
       "      <td>0.453851</td>\n",
       "      <td>0.651768</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043619</td>\n",
       "      <td>0.953864</td>\n",
       "      <td>0.975513</td>\n",
       "      <td>0.990321</td>\n",
       "      <td>1.042829</td>\n",
       "      <td>0.950362</td>\n",
       "      <td>1.015744</td>\n",
       "      <td>0.967266</td>\n",
       "      <td>0.929367</td>\n",
       "      <td>1.004862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>996782</td>\n",
       "      <td>win</td>\n",
       "      <td>0.714020</td>\n",
       "      <td>0.346666</td>\n",
       "      <td>0.543389</td>\n",
       "      <td>0.669854</td>\n",
       "      <td>0.706112</td>\n",
       "      <td>0.847998</td>\n",
       "      <td>0.625539</td>\n",
       "      <td>0.694811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884673</td>\n",
       "      <td>0.928013</td>\n",
       "      <td>0.740692</td>\n",
       "      <td>0.719947</td>\n",
       "      <td>0.821392</td>\n",
       "      <td>1.008698</td>\n",
       "      <td>0.689055</td>\n",
       "      <td>1.015462</td>\n",
       "      <td>0.756253</td>\n",
       "      <td>0.636618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8134 rows × 2276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample_id     class  autocorr_lag1_1  autocorr_lag1_2  autocorr_lag1_3  \\\n",
       "0       100206       0bk         0.893819         0.464748         0.603468   \n",
       "1       100206       2bk         0.861421         0.487011         0.484680   \n",
       "2       100206      fear         0.787456         0.512411         0.583106   \n",
       "3       100206         l         0.828420         0.447045         0.599733   \n",
       "4       100206      loss         0.841642         0.583493         0.632507   \n",
       "...        ...       ...              ...              ...              ...   \n",
       "8129    996782         r         0.727708         0.426522         0.565467   \n",
       "8130    996782  relation         0.792886         0.503521         0.550323   \n",
       "8131    996782       rnd         0.695992         0.790285         0.441623   \n",
       "8132    996782     story         0.759290         0.656334         0.785014   \n",
       "8133    996782       win         0.714020         0.346666         0.543389   \n",
       "\n",
       "      autocorr_lag1_4  autocorr_lag1_5  autocorr_lag1_6  autocorr_lag1_7  \\\n",
       "0            0.851265         0.786838         0.909225         0.675615   \n",
       "1            0.790721         0.769333         0.888625         0.603071   \n",
       "2            0.750800         0.637945         0.806604         0.628705   \n",
       "3            0.779001         0.749867         0.697426         0.494070   \n",
       "4            0.794625         0.773274         0.822869         0.459484   \n",
       "...               ...              ...              ...              ...   \n",
       "8129         0.729745         0.741279         0.681953         0.512494   \n",
       "8130         0.794583         0.793159         0.763781         0.657890   \n",
       "8131         0.634431         0.858011         0.865658         0.607152   \n",
       "8132         0.829183         0.825330         0.800928         0.453851   \n",
       "8133         0.669854         0.706112         0.847998         0.625539   \n",
       "\n",
       "      autocorr_lag1_8  ...   std_370   std_371   std_372   std_373   std_374  \\\n",
       "0            0.695618  ...  0.960313  0.935202  0.898046  1.023829  1.020021   \n",
       "1            0.553682  ...  0.957964  0.962293  0.957600  0.960843  0.924773   \n",
       "2            0.632117  ...  1.018323  1.066575  1.043297  0.910316  0.977589   \n",
       "3            0.672157  ...  0.929404  0.994043  0.921388  0.944134  1.049938   \n",
       "4            0.604053  ...  0.955303  0.976240  0.961123  0.988804  1.013960   \n",
       "...               ...  ...       ...       ...       ...       ...       ...   \n",
       "8129         0.589251  ...  1.052960  0.964462  0.968415  1.021673  0.966433   \n",
       "8130         0.526877  ...  1.120857  1.036813  0.975302  1.024739  0.927820   \n",
       "8131         0.557471  ...  1.002791  0.872504  0.941104  1.008072  0.989134   \n",
       "8132         0.651768  ...  1.043619  0.953864  0.975513  0.990321  1.042829   \n",
       "8133         0.694811  ...  0.884673  0.928013  0.740692  0.719947  0.821392   \n",
       "\n",
       "       std_375   std_376   std_377   std_378   std_379  \n",
       "0     0.991788  0.950959  1.041028  0.951495  0.968369  \n",
       "1     0.929355  0.972268  0.979947  0.975403  0.987517  \n",
       "2     0.988025  1.001793  0.944066  0.993105  0.973372  \n",
       "3     1.028949  1.045922  0.959480  0.939064  0.869964  \n",
       "4     1.038079  0.979294  0.943085  0.854481  1.037637  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "8129  0.966144  1.033262  0.962946  0.927782  0.929914  \n",
       "8130  1.015248  0.927360  1.111079  1.036310  1.067334  \n",
       "8131  0.865046  0.962983  0.826940  0.882297  0.896415  \n",
       "8132  0.950362  1.015744  0.967266  0.929367  1.004862  \n",
       "8133  1.008698  0.689055  1.015462  0.756253  0.636618  \n",
       "\n",
       "[8134 rows x 2276 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data.columns = [f\"{feat}_{vertex}\" if vertex else feat for feat, vertex in data.columns]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a61e4640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего пар вершин: 71631\n"
     ]
    }
   ],
   "source": [
    "vertex_columns = np.arange(1, 380)\n",
    "vertex_pairs = list(combinations(vertex_columns, 2))\n",
    "total_pairs = len(vertex_pairs)\n",
    "print(f'Всего пар вершин: {total_pairs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5786be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def save_pairwise_dataset(pair,output_dir='pairwise_datasets'):\n",
    "    v1, v2 = pair\n",
    "    feature_types = ['mean', 'std', 'autocorr_lag1', 'n_peaks', 'mean_peak_amp', 'mean_interpeak_interval']\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    filename = os.path.join(output_dir, f'dataset_v{v1}_v{v2}.pkl')\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"File already exists: {filename} - Skip\")\n",
    "        return False\n",
    "\n",
    "    cols_to_extract = []\n",
    "    for feat in feature_types:\n",
    "        cols_to_extract.extend([f'{feat}_{v1}', f'{feat}_{v2}'])\n",
    "    cols_to_extract.extend(['class', 'sample_id'])\n",
    "    \n",
    "    try:\n",
    "        subset = data[cols_to_extract].copy()\n",
    "        \n",
    "        rename_dict = {}\n",
    "        for feat in feature_types:\n",
    "            rename_dict.update({\n",
    "                f'{feat}_{v1}': f'{feat}_v1',\n",
    "                f'{feat}_{v2}': f'{feat}_v2'\n",
    "            })\n",
    "        \n",
    "        subset.rename(columns=rename_dict, inplace=True)\n",
    "        subset.to_pickle(filename)\n",
    "        #print(f\"Successfully saved: {filename}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing pair ({v1}, {v2}): {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4fc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pairs_in_parallel(pairs, num_processes=None):\n",
    "    if num_processes is None:\n",
    "        num_processes = max(1, cpu_count() - 1)  \n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = list(tqdm(pool.imap(save_pairwise_dataset, pairs), total=len(pairs)))\n",
    "    success_count = sum(results)\n",
    "    print(f\"Успешно сохранено датасетов: {success_count}/{len(pairs)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc9f8d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 71631/71631 [02:00<00:00, 592.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    }
   ],
   "source": [
    "process_pairs_in_parallel(vertex_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d48356",
   "metadata": {},
   "source": [
    "# Create full correlation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1651d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(arr, target_length, padding_value=np.nan):\n",
    "    if arr.shape[-1] < target_length:\n",
    "        padding = np.full((arr.shape[0], arr.shape[1], target_length - arr.shape[2]), padding_value)\n",
    "        arr = np.concatenate([arr, padding], axis=2)  \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88075d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation_with_nan_handling(arr1, arr2):\n",
    "    valid_mask = ~np.isnan(arr1) & ~np.isnan(arr2)\n",
    "    return np.corrcoef(arr1[valid_mask], arr2[valid_mask])[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da79420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_id_type_and_class(filename):\n",
    "    base = os.path.basename(filename).replace('.pickle', '')\n",
    "    sample_id, data_type, cls = base.split('_')\n",
    "    return sample_id, data_type, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbcbf3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def build_correlation_graph_by_type(file_list, out_csv_path, desired_type=\"LR\", batch_size=20):\n",
    "    all_edges = []\n",
    "    count = 0\n",
    "\n",
    "    def save_batch(batch_data):\n",
    "        df = pd.DataFrame(batch_data, columns=[\"type\", \"pair\", \"class\", \"vertices\", \"weight\"])\n",
    "        if not os.path.exists(out_csv_path):\n",
    "            df.to_csv(out_csv_path, index=False, mode='w', header=True)\n",
    "        else:\n",
    "            df.to_csv(out_csv_path, index=False, mode='a', header=False)\n",
    "\n",
    "    for file_path in tqdm(file_list):\n",
    "        sample_id, data_type, cls = extract_id_type_and_class(file_path)\n",
    "        if data_type != desired_type:\n",
    "            continue\n",
    "\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        lengths = [arr.shape[1] for arr in data]\n",
    "        max_length = max(max(lengths), 37)\n",
    "        padded = []\n",
    "        for arr in data:\n",
    "            pad_width = max_length - arr.shape[1]\n",
    "            arr_padded = np.pad(arr,\n",
    "                                ((0, 0),           \n",
    "                                 (0, pad_width)),\n",
    "                                mode='constant',\n",
    "                                constant_values=0)\n",
    "            padded.append(arr_padded)\n",
    "\n",
    "        series = np.stack(padded, axis=0)\n",
    "        ts = series.transpose(1, 0, 2).reshape(series.shape[1], -1)\n",
    "        corr_matrix = np.corrcoef(ts)\n",
    "        n_vertices = ts.shape[0]\n",
    "\n",
    "        for i in range(n_vertices):\n",
    "            for j in range(i + 1, n_vertices):\n",
    "                vertex_str = f\"v{i}_v{j}\"\n",
    "                weight = corr_matrix[i, j]\n",
    "                pair_id = sample_id  \n",
    "                all_edges.append((data_type, pair_id, cls, vertex_str, weight))\n",
    "\n",
    "        count += 1\n",
    "        if count >= batch_size:\n",
    "            save_batch(all_edges)\n",
    "            all_edges.clear()  \n",
    "            count = 0\n",
    "\n",
    "    if all_edges:\n",
    "        save_batch(all_edges)\n",
    "\n",
    "    print(f\"[{desired_type}] Сохранено: {out_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob(\"split_mean/**/*.pickle\", recursive=True)\n",
    "files = [file for file in files if 'LR' in os.path.basename(file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33407455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8134/8134 [36:11<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Сохранено: graph_LR.csv\n"
     ]
    }
   ],
   "source": [
    "build_correlation_graph_by_type(files, \"graph_LR.csv\", desired_type=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84523bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "emote_files = [file for file in files if ('fear' or 'neut') in os.path.basename(file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcae8652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 581/581 [03:56<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Сохранено: graph_emotions_LR.csv\n"
     ]
    }
   ],
   "source": [
    "build_correlation_graph_by_type(emote_files, \"graph_emotions_LR.csv\", desired_type=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea191c3",
   "metadata": {},
   "source": [
    "# Creating pairwise datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a111a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairwise_dataset(base_dir, features):\n",
    "    pattern = os.path.join(base_dir, '**', '*.pickle')\n",
    "    pickle_files = glob.glob(pattern, recursive=True)\n",
    "    all_files = []\n",
    "    for file_path in pickle_files:\n",
    "        data = pd.read_pickle(file_path)\n",
    "        class_label = file_path.split('_')[4].replace('.pickle', '')\n",
    "        data['class'] = class_label\n",
    "        data['sample_id'] = (file_path.split('/')[3]).split('_')[0]\n",
    "        all_files.append(data)\n",
    "\n",
    "\n",
    "    full_data = pd.concat(all_files)\n",
    "    full_data.reset_index(inplace=True)\n",
    "    full_data.rename(columns={'index': 'vertex'}, inplace=True)\n",
    "    full_data['vertex'] += 1\n",
    "    data = full_data.pivot_table(index=['sample_id', 'class'],\n",
    "                              columns='vertex',\n",
    "                              values=['mean', 'std'])\n",
    "    data.reset_index(inplace=True)\n",
    "    data.columns = [f\"{feat}_{vertex}\" if vertex else feat for feat, vertex in data.columns]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f49fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pairwise_dataset(pair, output_dir, feature_types, data):\n",
    "    v1, v2 = pair\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    filename = os.path.join(output_dir, f'dataset_v{v1}_v{v2}.pkl')\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"File already exists: {filename} - Skipping processing\")\n",
    "        return False\n",
    "\n",
    "    cols_to_extract = []\n",
    "    for feat in feature_types:\n",
    "        cols_to_extract.extend([f'{feat}_{v1}', f'{feat}_{v2}'])\n",
    "    cols_to_extract.extend(['class', 'sample_id'])\n",
    "    \n",
    "    try:\n",
    "        subset = data[cols_to_extract].copy()\n",
    "        \n",
    "        rename_dict = {}\n",
    "        for feat in feature_types:\n",
    "            rename_dict.update({\n",
    "                f'{feat}_{v1}': f'{feat}_v1',\n",
    "                f'{feat}_{v2}': f'{feat}_v2'\n",
    "            })\n",
    "        \n",
    "        subset.rename(columns=rename_dict, inplace=True)\n",
    "        subset.to_pickle(filename)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing pair ({v1}, {v2}): {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "def process_pairs_in_parallel(pairs, output_dir, feature_types, data, num_processes=None):\n",
    "    if num_processes is None:\n",
    "        num_processes = max(1, cpu_count() - 1)\n",
    "\n",
    "    args = [\n",
    "        (pair, output_dir, feature_types, data)\n",
    "        for pair in pairs\n",
    "    ]\n",
    "\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = list(\n",
    "            tqdm(pool.starmap(save_pairwise_dataset, args), total=len(args))\n",
    "        )\n",
    "\n",
    "    success_count = sum(results)\n",
    "    print(f\"Успешно сохранено датасетов: {success_count}/{len(pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa26ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 3232646.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/SOCIAL/LR'  \n",
    "output_dir = 'pairwise_social'\n",
    "features = ['mean', 'std']\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "number_of_vertices = 380\n",
    "vertex_columns = np.arange(1, number_of_vertices)\n",
    "vertex_pairs = list(combinations(vertex_columns, 2))\n",
    "total_pairs = len(vertex_pairs)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6053eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 2259065.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/RELATIONAL/LR'  \n",
    "output_dir = 'pairwise_relational'\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb8aeb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 3066080.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/MOTOR/LR'  \n",
    "output_dir = 'pairwise_motor_LR'\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3952ce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 2339710.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/LANGUAGE/LR'  \n",
    "output_dir = 'pairwise_language_LR'\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bc57987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 4787160.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/GAMBLING/LR'  \n",
    "output_dir = 'pairwise_gambling_LR'\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30806b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 3334948.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/EMOTIONAL/RL'  \n",
    "output_dir = 'pairwise_emotional_RL'\n",
    "features = ['mean', 'std']\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "number_of_vertices = 380\n",
    "vertex_columns = np.arange(1, number_of_vertices)\n",
    "vertex_pairs = list(combinations(vertex_columns, 2))\n",
    "total_pairs = len(vertex_pairs)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff64ead8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir = 'vertices_mean_extended/GAMBLING/RL'  \n",
    "output_dir = 'pairwise_gambling_RL'\n",
    "features = ['mean', 'std']\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "number_of_vertices = 380\n",
    "vertex_columns = np.arange(1, number_of_vertices)\n",
    "vertex_pairs = list(combinations(vertex_columns, 2))\n",
    "total_pairs = len(vertex_pairs)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f16eff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 1847499.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/LANGUAGE/RL'  \n",
    "output_dir = 'pairwise_language_RL'\n",
    "features = ['mean', 'std']\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "number_of_vertices = 380\n",
    "vertex_columns = np.arange(1, number_of_vertices)\n",
    "vertex_pairs = list(combinations(vertex_columns, 2))\n",
    "total_pairs = len(vertex_pairs)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b33998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 4592653.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/MOTOR/RL'  \n",
    "output_dir = 'pairwise_motor_RL'\n",
    "features = ['mean', 'std']\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "number_of_vertices = 380\n",
    "vertex_columns = np.arange(1, number_of_vertices)\n",
    "vertex_pairs = list(combinations(vertex_columns, 2))\n",
    "total_pairs = len(vertex_pairs)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd449016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 3544747.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/RELATIONAL/RL'  \n",
    "output_dir = 'pairwise_relational_RL'\n",
    "features = ['mean', 'std']\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "number_of_vertices = 380\n",
    "vertex_columns = np.arange(1, number_of_vertices)\n",
    "vertex_pairs = list(combinations(vertex_columns, 2))\n",
    "total_pairs = len(vertex_pairs)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54505c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 3374655.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/SOCIAL/RL'  \n",
    "output_dir = 'pairwise_social_RL'\n",
    "features = ['mean', 'std']\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "number_of_vertices = 380\n",
    "vertex_columns = np.arange(1, number_of_vertices)\n",
    "vertex_pairs = list(combinations(vertex_columns, 2))\n",
    "total_pairs = len(vertex_pairs)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18e6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 71631/71631 [00:00<00:00, 3159788.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно сохранено датасетов: 71631/71631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'vertices_mean_extended/WM/RL'  \n",
    "output_dir = 'pairwise_wm_RL'\n",
    "features = ['mean', 'std']\n",
    "data = create_pairwise_dataset(base_dir, features)\n",
    "number_of_vertices = 380\n",
    "vertex_columns = np.arange(1, number_of_vertices)\n",
    "vertex_pairs = list(combinations(vertex_columns, 2))\n",
    "total_pairs = len(vertex_pairs)\n",
    "process_pairs_in_parallel(vertex_pairs, output_dir, features, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6828f",
   "metadata": {},
   "source": [
    "# Build correlation graphs per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06116056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_id_type_and_class(filename):\n",
    "    base = os.path.basename(filename)\n",
    "    name, _ = os.path.splitext(base)\n",
    "    sample_id, data_type, cls = name.split('_')\n",
    "    return sample_id, data_type, cls\n",
    "\n",
    "def save_correlations_per_file(file_list, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for file_path in tqdm(file_list, desc=f\"Processing files\"):\n",
    "        base = os.path.basename(file_path)\n",
    "        fname = os.path.splitext(base)[0]  \n",
    "        out_path = os.path.join(output_dir, f\"{fname}.pkl\")\n",
    "        if os.path.exists(out_path):\n",
    "            continue\n",
    "        sample_id, data_type, cls = extract_id_type_and_class(file_path)\n",
    "\n",
    "        if file_path.lower().endswith('.csv'):\n",
    "            df0 = pd.read_csv(file_path)\n",
    "            ts = df0.iloc[:, 1:].to_numpy()\n",
    "        else:\n",
    "            data = pd.read_pickle(file_path)\n",
    "            lengths = [arr.shape[1] for arr in data]\n",
    "            L = max(max(lengths), 37)\n",
    "            padded = []\n",
    "            for arr in data:\n",
    "                pad_len = L - arr.shape[1]\n",
    "                arr_p = np.pad(arr,\n",
    "                               ((0,0), (0,pad_len)),\n",
    "                               mode='constant', constant_values=0)\n",
    "                padded.append(arr_p)\n",
    "            mat = np.stack(padded, axis=0)        \n",
    "            ts = mat.transpose(1, 0, 2).reshape(mat.shape[1], -1)\n",
    "\n",
    "\n",
    "        corr_mat = np.corrcoef(ts)\n",
    "        n = corr_mat.shape[0]\n",
    "        edges = []\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                edges.append({\n",
    "                    'vertex_1': f'v{i}',\n",
    "                    'vertex_2': f'v{j}',\n",
    "                    'weight': corr_mat[i, j]\n",
    "                })\n",
    "\n",
    "        corr_df = pd.DataFrame(edges, columns=['vertex_1', 'vertex_2', 'weight'])\n",
    "\n",
    "        corr_df.to_pickle(out_path)\n",
    "\n",
    "    print(f\"Done: saved per-file PKLs into {output_dir}\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"split_mean/**/*.*\", recursive=True)\n",
    "save_correlations_per_file(files, output_dir=\"correlation_graphs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
